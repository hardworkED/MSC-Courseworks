{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017120dc-ee8a-4567-82b5-1e64b1f20891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from scipy import ndimage\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32600447-a55c-4337-bbeb-1623107fd03b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VGG16(nn.Module):\n",
    "    def __init__(self, num_class, rgb=True):\n",
    "        super(VGG16, self).__init__()\n",
    "        \n",
    "        self.name = 'VGG16'\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3 if rgb else 1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv5 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv6 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv8 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv9 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv11 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv13 = nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1)\n",
    "        self.maxpool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5)\n",
    "        )\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(4096, num_class),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = self.maxpool1(out)\n",
    "        out = F.relu(self.conv3(out))\n",
    "        out = F.relu(self.conv4(out))\n",
    "        out = self.maxpool2(out)\n",
    "        out = F.relu(self.conv5(out))\n",
    "        out = F.relu(self.conv6(out))\n",
    "        out = F.relu(self.conv7(out))\n",
    "        out = self.maxpool3(out)\n",
    "        out = F.relu(self.conv8(out))\n",
    "        out = F.relu(self.conv9(out))\n",
    "        out = F.relu(self.conv10(out))\n",
    "        out = self.maxpool4(out)\n",
    "        out = F.relu(self.conv11(out))\n",
    "        out = F.relu(self.conv12(out))\n",
    "        out = F.relu(self.conv13(out))\n",
    "        out = self.maxpool5(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548e1f39-d5a0-4bc8-a457-db53ad4e2de8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "        out += residual if self.downsample else x\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "    \n",
    "class ResNet34(nn.Module):\n",
    "    def __init__(self, num_class, resBlock, repeats=[3, 4, 6, 3], rgb=True):\n",
    "        super(ResNet34, self).__init__()\n",
    "        \n",
    "        self.in_channels = 64\n",
    "        self.name = 'ResNet'\n",
    "        \n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3 if rgb else 1, out_channels=64, kernel_size=5, stride=1, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.build_layer(resBlock, 64, repeats[0], stride=1)\n",
    "        self.layer2 = self.build_layer(resBlock, 128, repeats[1], stride=2)\n",
    "        self.layer3 = self.build_layer(resBlock, 256, repeats[2], stride=2)\n",
    "        self.layer4 = self.build_layer(resBlock, 512, repeats[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(3, stride=1)\n",
    "        self.fc = nn.Linear(512, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def build_layer(self, resBlock, out_channels, repeat, stride=1):\n",
    "        downsample  = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        ) if stride != 1 or self.in_channels != out_channels else None\n",
    "        \n",
    "        layers = [resBlock(self.in_channels, out_channels, stride, downsample)]\n",
    "        self.in_channels = out_channels\n",
    "        layers += [resBlock(self.in_channels, out_channels) for i in range(repeat-1)]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b0a2d9-a4b1-44c0-82f6-026ca0d97af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def show_train_hist(y1, y2, show=False, save=False, path='Train_hist.png'):\n",
    "    x = range(len(y1))\n",
    "    \n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(x, y1, label='Train')\n",
    "    plt.plot(x, y2, label='Test')\n",
    "\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "\n",
    "    plt.legend(loc=4)\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save:\n",
    "        plt.savefig(path)\n",
    "\n",
    "    if show:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352201ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST\n",
    "def get_data(batch_size=100, resize=32):\n",
    "    data_dir = './data/'\n",
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        # acquire through data without transform: \n",
    "        # train_data.data.reshape((50000*32*32, 3)).mean(axis=0)/255\n",
    "        # train_data.data.reshape((50000*32*32, 3)).std(axis=0)/255\n",
    "        transforms.Normalize(mean=(0.1307,), std=(0.3081,)), \n",
    "        transforms.Resize((resize, resize)),\n",
    "        transforms.Lambda(lambda x: x.view(1, resize, resize).expand(3, -1, -1)),\n",
    "    ])\n",
    "    train_data = datasets.MNIST(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = datasets.MNIST(root=data_dir, train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "27cb85b0-6a2b-44b0-b3fb-6cf7843ac6f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_test(Model, learning_rate, train_loader, test_loader):\n",
    "    print('Now traing model {} with learning rate of {}.'.format(Model.name, learning_rate))\n",
    "\n",
    "    # initialise the device for training, if gpu is available, device = 'cuda', else: device = 'cpu'\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    save_dir = './MNIST_{}_results/'.format(Model.name)\n",
    "\n",
    "    # create folder if not exist\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.mkdir(save_dir)\n",
    "\n",
    "\n",
    "    # training parameters\n",
    "    epochs = 20\n",
    "\n",
    "    # declare the networks\n",
    "    model = Model.to(device)\n",
    "\n",
    "    # Cross Entropy Loss function and Adam optimizer\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # tracking variables\n",
    "    train_hist = {}\n",
    "    train_hist['train_losses'] = []\n",
    "    train_hist['test_losses'] = []\n",
    "    train_hist['train_acc'] = []\n",
    "    train_hist['test_acc'] = []\n",
    "\n",
    "    # logging\n",
    "    writer = SummaryWriter(comment='-lr{}e{}_{}'.format(learning_rate, epochs, Model.name))\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(epochs):\n",
    "        # training\n",
    "        Loss = []\n",
    "        epoch_start_time = time.time()\n",
    "        Acc = []\n",
    "        print('Training...')\n",
    "        for (image, label) in tqdm(train_loader):\n",
    "            model.train()\n",
    "            image = image.to(device)\n",
    "            label = label.to(device)\n",
    "\n",
    "            output = model(image)\n",
    "\n",
    "            # compute the loss\n",
    "            loss = criterion(output, label)\n",
    "            \n",
    "            # compute accuracy\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "            Acc.append((pred == label).sum().item() / pred.shape[0])\n",
    "\n",
    "            # back propagation\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # store the loss of each iter\n",
    "            Loss.append(loss.item())\n",
    "\n",
    "            # release GPU memory\n",
    "            del image, label, output, loss, pred\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        epoch_loss = np.mean(Loss)  # mean loss for the epoch\n",
    "        epoch_acc = np.mean(Acc)    # mean accuracy for the epoch\n",
    "        epoch_end_time = time.time()\n",
    "        per_epoch_ptime = epoch_end_time - epoch_start_time\n",
    "\n",
    "        # logging\n",
    "        train_hist['train_losses'].append(epoch_loss)\n",
    "        train_hist['train_acc'].append(epoch_acc)\n",
    "        writer.add_scalar('Loss/train', epoch_loss, epoch + 1)\n",
    "        writer.add_scalar('Accuracy/train', epoch_acc, epoch + 1)\n",
    "        writer.add_scalar('TimeTaken/train', per_epoch_ptime, epoch + 1)\n",
    "\n",
    "        print(\"Epoch %d of %d with %.2f s\" % (epoch + 1, epochs, per_epoch_ptime))\n",
    "        print(\"Loss: %.8f\" % (epoch_loss))\n",
    "        \n",
    "        # testing\n",
    "        with torch.no_grad():\n",
    "            print('Testing...')\n",
    "            model.eval()\n",
    "            pred_true = 0\n",
    "            Acc = []\n",
    "            Loss = []\n",
    "            for (image, label) in tqdm(test_loader):\n",
    "                image = image.to(device)\n",
    "                label = label.to(device)\n",
    "\n",
    "                output = model(image)\n",
    "                _, pred = torch.max(output.data, 1)\n",
    "                Acc.append((pred == label).sum().item() / pred.shape[0])\n",
    "                loss = criterion(output, label)\n",
    "                Loss.append(loss.item())\n",
    "                del image, label, output\n",
    "\n",
    "            # logging\n",
    "            epoch_loss = np.mean(Loss)  # mean loss for the epoch\n",
    "            epoch_acc = np.mean(Acc)    # mean accuracy for the epoch\n",
    "            writer.add_scalar('Loss/test', epoch_loss, epoch + 1)\n",
    "            writer.add_scalar('Accuracy/test', epoch_acc, epoch + 1)\n",
    "            train_hist['test_losses'].append(epoch_loss)\n",
    "            train_hist['test_acc'].append(epoch_acc)\n",
    "\n",
    "    end_time = time.time()\n",
    "    \n",
    "    print(\"Training finish!... save training results\")\n",
    "    show_train_hist(train_hist['train_losses'], train_hist['test_losses'], save=True, path=save_dir + 'lr{}e{}'.format(learning_rate, epochs) + '_loss_hist.png')\n",
    "    show_train_hist(train_hist['train_acc'], train_hist['test_acc'], save=True, path=save_dir + 'lr{}e{}'.format(learning_rate, epochs) + '_acc_hist.png')\n",
    "    torch.save(model.state_dict(), save_dir + 'lr{}e{}_{}'.format(learning_rate, epochs, Model.name) + '.model')\n",
    "    \n",
    "    del model\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "    # clear cell's output\n",
    "    clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a7017b-0852-4d9c-9ab5-462870370cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    # parameters for Models\n",
    "    num_class = 10\n",
    "    LRs = [0.000001, 0.0000001, 0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
    "    train_loader, test_loader = get_data()\n",
    "    \n",
    "    for lr in LRs:\n",
    "        vgg16 = VGG16(num_class)\n",
    "        resnet = ResNet34(num_class, ResBlock)\n",
    "        train_test(vgg16, lr, train_loader, test_loader)\n",
    "        train_test(resnet, lr, train_loader, test_loader)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc48e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIFAR-10\n",
    "def get_data(batch_size=100, resize=32):\n",
    "    data_dir = './data/'\n",
    "    # construct the dataset and data loader\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(), \n",
    "        # acquire through data without transform: \n",
    "        # train_data.data.reshape((50000*32*32, 3)).mean(axis=0)/255\n",
    "        # train_data.data.reshape((50000*32*32, 3)).std(axis=0)/255\n",
    "        transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.247, 0.2435, 0.2616)), \n",
    "    ])\n",
    "    train_data = datasets.CIFAR10(root=data_dir, train=True, transform=transform, download=True)\n",
    "    train_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\n",
    "    test_data = datasets.CIFAR10(root=data_dir, train=False, transform=transform, download=True)\n",
    "    test_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class = 10\n",
    "train_loader, test_loader = get_data()\n",
    "vgg16 = VGG16(num_class)\n",
    "resnet = ResNet34(num_class, ResBlock)\n",
    "train_test(vgg16, 0.00001, train_loader, test_loader)\n",
    "train_test(resnet, 0.000001, train_loader, test_loader)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1827730-a8db-4acd-972a-0fffab240f99",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
